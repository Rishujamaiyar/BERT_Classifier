{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Text Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_smE82YSYd7"
      },
      "source": [
        "### Installing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-YbjCkzw0yU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7bbae8-997c-441b-9bd4-a0c4d94dd876"
      },
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U tensorflow-text\n",
        "!pip install -q tf-models-official\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import spatial\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.4 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 213 kB 50.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 52 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 38.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 36.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 40.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 36.4 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUAruYDoSVK0"
      },
      "source": [
        "### Loading the Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpyJgMUjStO5"
      },
      "source": [
        "df = pd.read_excel(\"Training_data.xlsx\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['title'],df['label'], stratify=df['label'],test_size=0.2)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVuMSDNXOOfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d84f7e6-3e31-42ec-bc58-d4358f01fff1"
      },
      "source": [
        "#BERT\n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\", name='Preprocessing')\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\",trainable=True,name='BERT_encoder')\n",
        "\n",
        "# Bert layers\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "# Neural network layers\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "l = tf.keras.layers.Dense(1, activation=None, name=\"classifier\")(l)\n",
        "\n",
        "# Use inputs and outputs to construct a final model\n",
        "model = tf.keras.Model(inputs=[text_input], outputs = [l])\n",
        "print(\"Model Summary:\")\n",
        "print(model.summary())\n",
        "\n",
        "#Setting Parameters for training\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.BinaryAccuracy()\n",
        "epochs = 10\n",
        "steps_per_epoch = 3\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                            num_train_steps=num_train_steps,\n",
        "                                            num_warmup_steps=num_warmup_steps,\n",
        "                                            optimizer_type='adamw')\n",
        "  \n",
        "model.compile(optimizer= optimizer,\n",
        "                loss= loss,\n",
        "                metrics=metrics)\n",
        "\n",
        "#Model training\n",
        "model.fit(X_train, y_train, epochs = epochs)\n",
        "\n",
        "#Model testing\n",
        "scores_test = model.predict(X_test)\n",
        "y_pred = []\n",
        "\n",
        "#Taking cut-off as 0.7\n",
        "for each in scores_test:\n",
        "    if(each>0.7):\n",
        "      y_pred.append(1)\n",
        "    else:\n",
        "      y_pred.append(0)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Summary:\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Preprocessing (KerasLayer)      {'input_mask': (None 0           text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "BERT_encoder (KerasLayer)       {'encoder_outputs':  109482241   Preprocessing[0][0]              \n",
            "                                                                 Preprocessing[0][1]              \n",
            "                                                                 Preprocessing[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 768)          0           BERT_encoder[0][13]              \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (None, 1)            769         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - 29s 1s/step - loss: 0.7453 - binary_accuracy: 0.4412\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.6770 - binary_accuracy: 0.5956\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.6342 - binary_accuracy: 0.6471\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.5558 - binary_accuracy: 0.7500\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.5051 - binary_accuracy: 0.8015\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.4858 - binary_accuracy: 0.8088\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.4829 - binary_accuracy: 0.8382\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.4774 - binary_accuracy: 0.8235\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.4788 - binary_accuracy: 0.8088\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.4941 - binary_accuracy: 0.8382\n",
            "Confusion Matrix:\n",
            "[[11  3]\n",
            " [ 8 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO7uGmFRTTS9"
      },
      "source": [
        "### Validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XzbqxB4gV12",
        "outputId": "f157305a-38a6-47cd-c0b6-099278b63e13"
      },
      "source": [
        "df_val = pd.read_excel(\"Validation_data.xlsx\")\n",
        "X_val = df_val['title']\n",
        "y_val = df_val['label']\n",
        "\n",
        "\n",
        "#Model validation\n",
        "scores_val = model.predict(X_val)\n",
        "\n",
        "\n",
        "y_pred = []\n",
        "for each in scores_val:\n",
        "    if(each>0.7):\n",
        "      y_pred.append(1)\n",
        "    else:\n",
        "      y_pred.append(0)\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[46 18]\n",
            " [ 0 13]]\n"
          ]
        }
      ]
    }
  ]
}